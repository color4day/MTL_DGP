{
 "cells": [
  {
   "cell_type": "code",
   "id": "c1c764c9-b1d3-4418-8b28-ceffbb97846d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.516590Z",
     "start_time": "2024-06-07T01:12:37.410537Z"
    }
   },
   "source": [
    "import os\n",
    "import pyro\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from torch import Tensor\n",
    "from tqdm.auto import trange\n",
    "from pyro.nn import PyroModule, PyroSample, PyroParam\n",
    "from pyro.infer import MCMC, NUTS, SVI, Trace_ELBO, Predictive\n",
    "from pyro.distributions import constraints\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "\n",
    "from src.dgp_rff.outer_layer import SingleGP, SingleCauchyGP"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.546830Z",
     "start_time": "2024-06-07T01:12:40.517596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "# trouble shoot see this link:https://stackoverflow.com/questions/77068908/how-to-install-pytorch-with-cuda-support-on-windows-11-cuda-12-no-matching"
   ],
   "id": "f56a04aab430ee20",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.553749Z",
     "start_time": "2024-06-07T01:12:40.547835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.current_device()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)\n",
    "# cuda = torch.device('cuda') "
   ],
   "id": "e4ffde22a3c33392",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.715390Z",
     "start_time": "2024-06-07T01:12:40.554999Z"
    }
   },
   "cell_type": "code",
   "source": "var1= torch.FloatTensor([1.0,2.0,3.0]).cuda()",
   "id": "463b9382a4096407",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.721975Z",
     "start_time": "2024-06-07T01:12:40.717395Z"
    }
   },
   "cell_type": "code",
   "source": "var1.device",
   "id": "be0e909f3f4b15e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.728804Z",
     "start_time": "2024-06-07T01:12:40.723418Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.memory_allocated()",
   "id": "f0a13e24b00d76c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "  # Next step\n",
    "\n",
    "0. Get familiar with the coding structure\n",
    "1. CPU -> GPU\n",
    "2. Last step without bias\n",
    "3. Figure out how they train\n",
    "4. How to access the posterior mean and std/scale from the model\n",
    "5. Learn pickle: numpy.ndarray, png\n",
    "6. ....\n",
    "7. construct a DeepGP class"
   ],
   "id": "858c7a1400939da9"
  },
  {
   "cell_type": "code",
   "id": "f88c1c9b-ced6-45cf-ae43-59c6cad2d4b1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.770745Z",
     "start_time": "2024-06-07T01:12:40.729810Z"
    }
   },
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Read data\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "X_train_path = os.path.join(cwd, \"folds\", \"synthetic_1_fold_1_X_train.txt\")\n",
    "X_test_path = os.path.join(cwd, \"folds\", \"synthetic_1_fold_1_X_test.txt\")\n",
    "Y_train_path = os.path.join(cwd, \"folds\", \"synthetic_1_fold_1_Y_train.txt\")\n",
    "Y_test_path = os.path.join(cwd, \"folds\", \"synthetic_1_fold_1_Y_test.txt\")\n",
    "\n",
    "x_obs = np.loadtxt(X_train_path)\n",
    "y_obs = np.loadtxt(Y_train_path)\n",
    "x_val = np.loadtxt(X_test_path)\n",
    "y_val = np.loadtxt(Y_test_path)\n",
    "\n",
    "# Set plot limits and labels\n",
    "xlims = [-0.2, 0.2]\n",
    "\n",
    "# The X and Y have to be at least 2-dim\n",
    "x_train = torch.from_numpy(x_obs).float().reshape(-1,1)\n",
    "y_train = torch.from_numpy(y_obs).float()\n",
    "x_test = torch.from_numpy(x_val).float().reshape(-1,1)\n",
    "y_test = torch.from_numpy(y_val).float()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuanq\\OneDrive\\Desktopold\\SB\\research\\DGPII\\program\\DGP-RFF-main\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b2e48051c40fa594"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.775692Z",
     "start_time": "2024-06-07T01:12:40.772262Z"
    }
   },
   "cell_type": "code",
   "source": "x_train = x_train.cuda()\n",
   "id": "86d4033f31f79e6e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.783212Z",
     "start_time": "2024-06-07T01:12:40.776699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train = y_train.cuda()\n",
    "x_test = x_test.cuda()\n",
    "y_test = y_test.cuda()"
   ],
   "id": "dc3487e3dd203d23",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.789602Z",
     "start_time": "2024-06-07T01:12:40.784726Z"
    }
   },
   "cell_type": "code",
   "source": "x_train.device",
   "id": "7bbe951cd01dbbc3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d95fdaea-f245-423b-ac9d-6c527ae8bd14",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.796033Z",
     "start_time": "2024-06-07T01:12:40.790609Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "  # X = [\n",
    "#     [1,2,3],\n",
    "#     [4,5,6,7,8]\n",
    "#     ]\n",
    "# X_path = os.path.join(cwd, \"folds\", \"test.pickle\")\n",
    "# with open(X_path, 'wb') as f:\n",
    "#     pickle.dump(X, f)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "f1c587d2-82ff-41b9-aa8a-3752c050afd3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.801341Z",
     "start_time": "2024-06-07T01:12:40.798041Z"
    }
   },
   "source": [
    "# with open(X_path, 'rb') as f:\n",
    "#     X_read = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "4d60fd52-887a-4ca5-9b03-8c4777801f8c",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:40.808534Z",
     "start_time": "2024-06-07T01:12:40.802856Z"
    }
   },
   "source": [
    "class Model(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, J=50):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.out_dim = out_dim\n",
    "        self.model = SingleGP(in_dim, out_dim, J)\n",
    "        self.model.to('cuda')\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        mu = self.model(x).squeeze() #10000*6\n",
    "        \n",
    "        # batch shape | event shapt\n",
    "        # 10000       |\n",
    "        \n",
    "        scale = pyro.sample(\"sigma\", dist.Gamma(torch.tensor(0.5, device='cuda'), torch.tensor(1.0, device='cuda'))).expand(self.out_dim)  # Infer the response noise\n",
    "\n",
    "        # Sampling model\n",
    "        with pyro.plate(\"data\", x.shape[0]): # x.shape[0]=10000\n",
    "            # obs = xxx(\"obs\", mu, obs=y)\n",
    "            obs = pyro.sample(\"obs\", dist.MultivariateNormal(mu.cuda(), torch.diag(scale * scale).cuda()), obs=y)\n",
    "            \n",
    "#         f1: phi(Omega x)W (+ epsilon1)\n",
    "#         f2: phi(Omega f1)W (+ epsilon2)\n",
    "        \n",
    "#         f2 + epsilon ~ N(0, Sigma)\n",
    "            \n",
    "        return mu"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "71f9724a8eb2b703",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-07T01:12:43.052145Z",
     "start_time": "2024-06-07T01:12:40.812045Z"
    }
   },
   "source": [
    "model = Model(in_dim=x_train.shape[1], out_dim=y_train.shape[1], J=50)\n",
    "model = model.to('cuda')"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.cuda.FloatTensor' as parameter 'weight' (torch.nn.Parameter or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m Model(in_dim\u001B[38;5;241m=\u001B[39mx_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], out_dim\u001B[38;5;241m=\u001B[39my_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], J\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[0;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[13], line 6\u001B[0m, in \u001B[0;36mModel.__init__\u001B[1;34m(self, in_dim, out_dim, J)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_dim \u001B[38;5;241m=\u001B[39m out_dim\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m SingleGP(in_dim, out_dim, J)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\OneDrive\\Desktopold\\SB\\research\\DGPII\\program\\DGP-RFF-main\\src\\dgp_rff\\outer_layer.py:46\u001B[0m, in \u001B[0;36mSingleGP.__init__\u001B[1;34m(self, in_dim, out_dim, J, init_w)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m in_dim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m out_dim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m J \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m  \u001B[38;5;66;03m# make sure the dimensions are valid\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# Define the PyroModule layer list\u001B[39;00m\n\u001B[1;32m---> 46\u001B[0m layer_list \u001B[38;5;241m=\u001B[39m [FirstLayer(in_dim, \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m J), SecondLayertest(\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m J, out_dim,init_w)]\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers \u001B[38;5;241m=\u001B[39m PyroModule[torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModuleList](layer_list)\n",
      "File \u001B[1;32m~\\OneDrive\\Desktopold\\SB\\research\\DGPII\\program\\DGP-RFF-main\\src\\dgp_rff\\inner_layer.py:70\u001B[0m, in \u001B[0;36mFirstLayer.__init__\u001B[1;34m(self, in_dim, hid_dim)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mJ \u001B[38;5;241m=\u001B[39m hid_dim \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer \u001B[38;5;241m=\u001B[39m PyroModule[nn\u001B[38;5;241m.\u001B[39mLinear](in_dim, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mJ, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 70\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m pyro\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabc\u001B[39m\u001B[38;5;124m\"\u001B[39m,dist\u001B[38;5;241m.\u001B[39mNormal(\u001B[38;5;241m0.\u001B[39m, \u001B[38;5;241m1.\u001B[39m)\u001B[38;5;241m.\u001B[39mexpand([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mJ, in_dim])\u001B[38;5;241m.\u001B[39mto_event(\u001B[38;5;241m2\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pyro\\nn\\module.py:630\u001B[0m, in \u001B[0;36mPyroModule.__setattr__\u001B[1;34m(self, name, value)\u001B[0m\n\u001B[0;32m    627\u001B[0m     _pyro_samples[name] \u001B[38;5;241m=\u001B[39m value\u001B[38;5;241m.\u001B[39mprior\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(name, value)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1635\u001B[0m, in \u001B[0;36mModule.__setattr__\u001B[1;34m(self, name, value)\u001B[0m\n\u001B[0;32m   1633\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m params:\n\u001B[0;32m   1634\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1635\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot assign \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m as parameter \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1636\u001B[0m                         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(torch.nn.Parameter or None expected)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1637\u001B[0m                         \u001B[38;5;241m.\u001B[39mformat(torch\u001B[38;5;241m.\u001B[39mtypename(value), name))\n\u001B[0;32m   1638\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregister_parameter(name, value)\n\u001B[0;32m   1639\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot assign 'torch.cuda.FloatTensor' as parameter 'weight' (torch.nn.Parameter or None expected)"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean_field_guide = AutoDiagonalNormal(model)\n",
    "optimizer = pyro.optim.Adam({\"lr\": 0.001})\n",
    "\n",
    "svi = SVI(model, mean_field_guide, optimizer, loss=Trace_ELBO())\n",
    "pyro.clear_param_store()\n",
    "\n",
    "num_epochs = 250\n",
    "progress_bar = trange(num_epochs)\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    loss = svi.step(x_train, y_train)\n",
    "    progress_bar.set_postfix(loss=f\"{loss / x_train.shape[0]:.3f}\")"
   ],
   "id": "b3ecd508-5a6a-41ba-aac0-a5ffd711229a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.parameters()",
   "id": "b162f80e752f771f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8f9a0fc-eaba-49d6-b2b7-25d2900d464f",
   "metadata": {
    "tags": []
   },
   "source": [
    "predictive = Predictive(model, guide=mean_field_guide, num_samples=500)\n",
    "preds = predictive(x_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f9017b0-0419-4084-8a67-9e0a8d05a425",
   "metadata": {
    "tags": []
   },
   "source": "y_pred = preds['obs'].cpu().detach().numpy().mean(axis=0)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "74966241-fe23-4a9e-b720-3a2530374deb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "for d in range(6):\n",
    "    plt.plot(x_obs, y_obs[:,d], label=\"Observation\")\n",
    "    plt.plot(x_test.cpu(), y_pred[:,d], label=\"Prediction\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8588c70c-5a0c-4b44-b33c-f57244422bda",
   "metadata": {
    "tags": []
   },
   "source": [
    "# sampled Omega: model.model.layers[0].layer.weight"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82c6784c-e27f-4fbf-9b48-a2cfd21dbd1d",
   "metadata": {},
   "source": [
    "# preds['model.layers.0.layer.weight'].squeeze().mean(axis=0): Omega estimator"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f7383f0-d018-4491-a554-6bdee8840104",
   "metadata": {
    "tags": []
   },
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name).shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "\n",
    "# 定义两层BNN模型\n",
    "class BayesianNN(PyroModule):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        # 第一层权重和偏置\n",
    "        self.fc1 = PyroModule[nn.Linear](input_size, hidden_size)\n",
    "        self.fc1.weight = PyroSample(dist.Normal(0., 1.).expand([hidden_size, input_size]).to_event(2))\n",
    "        self.fc1.bias = PyroSample(dist.Normal(0., 1.).expand([hidden_size]).to_event(1))\n",
    "\n",
    "        # 第二层权重和偏置\n",
    "        self.fc2 = PyroModule[nn.Linear](hidden_size, output_size)\n",
    "        self.fc2.weight = PyroSample(dist.Normal(0., 1.).expand([output_size, hidden_size]).to_event(2))\n",
    "        self.fc2.bias = PyroSample(dist.Normal(0., 1.).expand([output_size]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        mean = self.fc2(x)\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 1.))\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean\n",
    "\n",
    "# 生成一些合成数据\n",
    "input_size = 6\n",
    "hidden_size = 10\n",
    "output_size = 1\n",
    "N = 100  # 样本数\n",
    "\n",
    "# 真实参数\n",
    "true_w1 = torch.randn(hidden_size, input_size)\n",
    "true_b1 = torch.randn(hidden_size)\n",
    "true_w2 = torch.randn(output_size, hidden_size)\n",
    "true_b2 = torch.randn(output_size)\n",
    "\n",
    "# 生成数据\n",
    "x_data = torch.randn(N, input_size)\n",
    "y_data = torch.relu(x_data @ true_w1.t() + true_b1) @ true_w2.t() + true_b2 + 0.1 * torch.randn(N, output_size)\n",
    "\n",
    "# 初始权重\n",
    "init_weight = torch.tensor([0.4, 0.2, 0.3, -0.4, 0.3, 0.2]).reshape(10, input_size)  # 修改为与hidden_size匹配\n",
    "\n",
    "# 定义引导函数\n",
    "def guide(x, y=None):\n",
    "    guide = BayesianNN(input_size, hidden_size, output_size)\n",
    "    guide.fc1.weight = PyroSample(dist.Normal(pyro.param(\"w1_loc\", init_weight),\n",
    "                                              pyro.param(\"w1_scale\", torch.ones([hidden_size, input_size]), constraint=dist.constraints.positive)).to_event(2))\n",
    "    guide.fc1.bias = PyroSample(dist.Normal(pyro.param(\"b1_loc\", torch.randn(hidden_size)),\n",
    "                                            pyro.param(\"b1_scale\", torch.ones(hidden_size), constraint=dist.constraints.positive)).to_event(1))\n",
    "    guide.fc2.weight = PyroSample(dist.Normal(pyro.param(\"w2_loc\", torch.randn(output_size, hidden_size)),\n",
    "                                              pyro.param(\"w2_scale\", torch.ones(output_size, hidden_size), constraint=dist.constraints.positive)).to_event(2))\n",
    "    guide.fc2.bias = PyroSample(dist.Normal(pyro.param(\"b2_loc\", torch.randn(output_size)),\n",
    "                                            pyro.param(\"b2_scale\", torch.ones(output_size), constraint=dist.constraints.positive)).to_event(1))\n",
    "    return guide\n",
    "\n",
    "# 优化器和损失函数\n",
    "optimizer = Adam({\"lr\": 0.01})\n",
    "svi = SVI(BayesianNN(input_size, hidden_size, output_size), guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# 训练\n",
    "num_iterations = 1000\n",
    "for i in range(num_iterations):\n",
    "    loss = svi.step(x_data, y_data)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step {i} : loss = {loss}\")\n",
    "\n",
    "# 打印估计的参数键和值\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(f\"{name} : {value.detach().numpy()}\")\n"
   ],
   "id": "ed18f216ed15b578",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1 -> 50; 100 -> 6",
   "id": "ecb6e41e0a42d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Omega 1*50  1*50\n",
    "W     6*100 6*100\n",
    "bias  6     6\n",
    "sigma 1     1"
   ],
   "id": "2309648bcec46c90"
  },
  {
   "cell_type": "code",
   "id": "dc579bc1-39d1-4a15-b6b0-e6e86050b340",
   "metadata": {},
   "source": [
    "# def model(data):\n",
    "#   alpha = torch.tensor(6.0)\n",
    "#   beta = torch.tensor(10.0)\n",
    "#   pay_probs = pyro.sample('pay_probs', dist.Beta(alpha, beta).expand(3).independent(1))\n",
    "#   normalized_pay_probs = pay_probs / torch.sum(pay_probs)\n",
    "\n",
    "#   with pyro.iarange('data_loop', len(data)):\n",
    "#     pyro.sample('obs', dist.Categorical(probs=normalized_pay_probs), obs=data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca173da6-0f92-41fc-9b1b-5f15dbaa44d0",
   "metadata": {},
   "source": [
    "# def guide(data):\n",
    "#   alphas = pyro.param('alphas', torch.tensor(6.).expand(3), constraint=constraints.positive)\n",
    "#   betas = pyro.param('betas', torch.tensor(10.).expand(3), constraint=constraints.positive) \n",
    "\n",
    "#   pyro.sample('pay_probs', dist.Beta(alphas, betas).independent(1))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
